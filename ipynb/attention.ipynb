{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# pytroch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# utils\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import re\n",
    "from typing import Tuple\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "train = train.iloc[:100]\n",
    "train.drop([\"ID\", \"제품\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 숫자형 변수들의 min-max scaling을 수행하는 코드입니다.\n",
    "numeric_cols = train.columns[4:]\n",
    "# 칵 column의 min 및 max 계산\n",
    "min_values = train[numeric_cols].min(axis=1)\n",
    "max_values = train[numeric_cols].max(axis=1)\n",
    "# 각 행의 범위(max-min)를 계산하고, 범위가 0인 경우 1로 대체\n",
    "ranges = max_values - min_values\n",
    "ranges[ranges == 0] = 1\n",
    "# min-max scaling 수행\n",
    "train[numeric_cols] = (train[numeric_cols].subtract(min_values, axis=0)).div(ranges, axis=0)\n",
    "# max와 min 값을 dictionary 형태로 저장\n",
    "scale_min_dict = min_values.to_dict()\n",
    "scale_max_dict = max_values.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "categorical_col = [\"대분류\", \"중분류\", \"소분류\", \"브랜드\"]\n",
    "\n",
    "for col in categorical_col:\n",
    "    train[col] = encoder.fit_transform(train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_data(data, train_size=90, predict_size=21):\n",
    "    '''\n",
    "    학습 기간 블럭, 예측 기간 블럭의 세트로 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 학습에 활용할 기간\n",
    "    predict_size : 추론할 기간\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    window_size = train_size + predict_size\n",
    "    \n",
    "    input_data = np.empty((num_rows * (len(data.columns) - window_size + 1), train_size, len(data.iloc[0, :4]) + 1))\n",
    "    target_data = np.empty((num_rows * (len(data.columns) - window_size + 1), predict_size))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, 4:])\n",
    "        \n",
    "        for j in range(len(sales_data) - window_size + 1):\n",
    "            window = sales_data[j : j + window_size]\n",
    "            temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "            input_data[i * (len(data.columns) - window_size + 1) + j] = temp_data\n",
    "            target_data[i * (len(data.columns) - window_size + 1) + j] = window[train_size:]\n",
    "    \n",
    "    return input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predict_data(data, train_size=21):\n",
    "    '''\n",
    "    평가 데이터(Test Dataset)를 추론하기 위한 Input 데이터를 생성\n",
    "    data : 일별 판매량\n",
    "    train_size : 추론을 위해 필요한 일별 판매량 기간 (= 학습에 활용할 기간)\n",
    "    '''\n",
    "    num_rows = len(data)\n",
    "    \n",
    "    input_data = np.empty((num_rows, train_size, len(data.iloc[0, :4]) + 1))\n",
    "    \n",
    "    for i in tqdm(range(num_rows)):\n",
    "        encode_info = np.array(data.iloc[i, :4])\n",
    "        sales_data = np.array(data.iloc[i, -train_size:])\n",
    "        \n",
    "        window = sales_data[-train_size : ]\n",
    "        temp_data = np.column_stack((np.tile(encode_info, (train_size, 1)), window[:train_size]))\n",
    "        input_data[i] = temp_data\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea00048dc4748408c3910987d6f3f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512645ca86c942008eaf6ff06787ebe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_input, train_target = make_train_data(train)\n",
    "test_input = make_predict_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35300, 21)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Validation Split\n",
    "data_len = len(train_input)\n",
    "val_input = train_input[-int(data_len*0.2):]\n",
    "val_target = train_target[-int(data_len*0.2):]\n",
    "train_input = train_input[:-int(data_len*0.2)]\n",
    "train_target = train_target[:-int(data_len*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28240, 90, 5), (28240, 21), (7060, 90, 5), (7060, 21), (100, 21, 5))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, train_target.shape, val_input.shape, val_target.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.Y is not None:\n",
    "            return torch.Tensor(self.X[index]), torch.Tensor(self.Y[index])\n",
    "        return torch.Tensor(self.X[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_input, train_target)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 32, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = CustomDataset(val_input, val_target)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = 32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 90, 5])\n",
      "torch.Size([32, 21])\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataloader:\n",
    "    print(sample[0].shape)\n",
    "    print(sample[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mulitple Timeseries Forecasting \n",
    "\n",
    "-> 날씨 : 90일치가지고 하루 </br>\n",
    "-> 90일치로 21일을 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 구조\n",
    "    - 인코더\n",
    "    - 어텐션\n",
    "    - 디코더\n",
    "    - 시퀀스 투 시퀀스 with 어텐션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X : Batch_size, src_len, input_size\n",
    "- y : Batch_size, trg_len\n",
    "\n",
    "- 기계번역 소스 (원문)\n",
    "- src : source\n",
    "- trg : target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, enc_hid_dim: int, dec_hid_dim:int, n_layers: int, dropout: float):\n",
    "        '''\n",
    "        Seq2Seq with Attention -> 이게 정확한 모델 명칭\n",
    "        기존의 Seq2Seq 구조에서 어텐션을 결합하여 시계열 문제에서 발생할 수 있던 Long Term Dependecy 문제 해결시도\n",
    "        따라서 encoder에서 hidden state를 디코더로 전달, 디코더에서 인코더와 attention연산을 통하여 attention weight를 확보한다.\n",
    "        deocder에서 attention weight와 hidden state를 결합하여 모든 시퀀스에 대하여 집중을 할 수 있어졌음\n",
    "            -> 멀어질 수록 약해지던 Seq2Seq 문제 해결\n",
    "\n",
    "        parameter\n",
    "            - input_dim : input 차원\n",
    "            - enc_hid_dim : 인코더의 hidden_state 차원 -> 하이퍼파라미터 변경 필요\n",
    "            - dec_hid_dim : 디코더의 hidden_state 차원 -> 하이퍼파라미터 변경 필요\n",
    "               **주의 사항**\n",
    "                - 만약 enc_hid_dim과 dec_hid_dim이 일치하지 않을 때 에러 발생할 수 도 있음 -> 실험은 안해봤는데 그럴 가능성 존재 -> assert로 처리 혹은 그냥 모델 구성시 일치시키는 방안 추천\n",
    "            - n_layer : lstm 층을 몇개를 쌓을지\n",
    "            - dropout : dropout 확률\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        # 데이터 셋의 경우 [batch_size, window_size, input_size]로 구성되어 있음, 따라서 batch_first옵션을 True로 해야 에러가 발생안함\n",
    "        # 인코더 층에는 bidirectional 옵션을 걸었는데 이는 한방향 학습이 아닌 양방향 학습을 통해 더 정확한 정보를 전달하기 위함\n",
    "        # 만일 이 옵션을 False로 할경우 아래 Linear 층 곱하기를 제외하면 에러 해결 될듯? -> 확실치 않기 때문에 디버깅 필요\n",
    "        self.rnn = nn.LSTM(input_dim, enc_hid_dim, n_layers, bidirectional=True, batch_first=True)\n",
    "        self.fc_hidden = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.fc_cell = nn.Linear(enc_hid_dim * 2, dec_hid_dim)  \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # LSTM 의 경우 ouput과 hidden state, cell state 총 3가지를 반환\n",
    "        # 일반 LSTM 모델의 경우 output을 제외한 나머지 두개는 필요없기 때문에 output, _ = lstm(x)로 보통 사용하지만 이 경우 디코더에 시계열 정보를 넘겨줘야 하기 때문에 추가 연산을 통하여 넘겨줌\n",
    "        outputs, (hidden, cell) = self.rnn(src)\n",
    "        \n",
    "\n",
    "        # 카톡으로 보낸 사진 구현\n",
    "        hidden = torch.tanh(self.fc_hidden(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        cell = torch.tanh(self.fc_cell(torch.cat((cell[-2, :, :], cell[-1, :, :]), dim=1)))\n",
    "\n",
    "        return outputs, (hidden, cell)\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hid_dim: int, dec_hid_dim: int):\n",
    "\n",
    "        '''\n",
    "        다양한 어텐션이 존재, dot product 어텐션 부터, global 어텐션 등등.. 하지만 실력 부족으로 인한 concat 어텐션 밖에 구현... -> 금요일 전까지 다른 어텐션 코드 찾아볼 예정\n",
    "        enc_hid_dim : 인코더 히든 차원\n",
    "        dec_hid_dim : 디코더 히든 차원\n",
    "        어텐션의 경우 어텐션과 함께 value를 반환하여 이 두개를 통해 어텐션 가중치를 얻어야함\n",
    "        '''\n",
    "        super().__init__()\n",
    "        # 공식대로 구현\n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # encoder_outputs = [batch_size, src_len, input_size]\n",
    "        # 따라서 배치 사이즈와 타겟 길이를 추출\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        src_len = encoder_outputs.size(1)\n",
    "    \n",
    "        # 디버깅 상당히 오래한 부분\n",
    "        # squeeze를 통하여 먼저 첫번째 차원을 제거하고 두번째 차원을 확장하면서 행렬 합을 할 수 있게 차원을 맞추는 부분\n",
    "        # 물론 대체 왜 아까 (1, 2880, 1) 인지는 이해하지 못하였지만 아무튼 해결\n",
    "        # print(f\"시작 hidden 의 크기 :{hidden.shape}\")\n",
    "        hidden = hidden.squeeze(0)\n",
    "        # print(f\"첫번째 차원을 없앤 hidden 의 크기 : {hidden.shape}\")\n",
    "        hidden = hidden.unsqueeze(1).expand(-1, src_len, -1)\n",
    "        # print(f\"차원을 맞춘 hidden 의 크기 : {hidden.shape}\")\n",
    "    \n",
    "        # 보통의 코드에서 energy라고 표현해서 변수명을 에너지로 사용\n",
    "        # 어텐션 가중치를 얻기 위하여 인코더의 출력과 인코더의 히든 스테이트를 행렬합을 하고 어텐션 계산을 통해 어텐션 벡터 구하는 과정\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        # 차원을 맞춰 최종 어텐션 스코어를 확보한다.\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        # 소프트 맥스를 적용하여 어텐션 스코어에서 어텐션 가중치를 확보한다. \n",
    "        return nn.functional.softmax(attention, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim: int, enc_hid_dim: int, dec_hid_dim: int, n_layers: int, dropout: float, attention: nn.Module):\n",
    "        '''\n",
    "        디코더의 경우 시퀀스투시퀀스 구조와 비슷하게 인코더에서 hidden_state를 입력받아 그것을 통하여 디코더에 생성 (주로 기계번역) 하지만 시퀀스가 길어지면 처음 넣었던 정보가 잘 담기지 못하는 long term dependency\n",
    "        문제 발생 따라서 디코더의 모든 차원에 어텐션 가중치를 더해 출력의 정확도를 높임\n",
    "        디코더 이기 때문에 마지막 출력 부분은 Linear 함수를 통하여 prediction값을 생성하도록 코딩하였음\n",
    "        \n",
    "        parameter \n",
    "            - output_dim : output_dim 출력 차원 21고정 상수값\n",
    "            - enc_hid_dim : 인코더 히든 차원 -> 하이퍼파라미터\n",
    "            - dec_hid_dim : 디코더 히든 차원 -> 하이퍼파라미터 -> 하지만 위에서 언급한것처럼 서로 다를때 실험안해봤기 때문에 서로 다를경우 제보 바랍니다.\n",
    "            - n_layer : 디코더 레이어 개수 -> 하이퍼파라미터 -> 쓰다보니 이것도 인코더랑 다르게 생성할 생각을 못했지만 혹시나 서로 다르면 에러 발생할 수 있기에 에러나면 제보 바랍니다.\n",
    "            - dropout : dropout prob\n",
    "            - attetntion : 어텐션 모듈을 불러와서 어텐션 가중치를 계산해야함\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        # target 값도 [batch_size, window_size]로 구성되어 있기 때문에 batch_first옵션을 사용\n",
    "        # 그래서 학습시 타겟의 차원을 늘려 [batch_size, window_size, 1]로 만들어줘야함 -> 학습코드에 추가했습니다\n",
    "        # 여기에서는 bidirectional 옵션을 사용하지 않고 default 값인 false로 하였는데 이걸 양방향으로 예측하는 경우는 아마 보지 못했는데 에러나면 제보 바랍니다.\n",
    "        self.rnn = nn.LSTM((enc_hid_dim * 2) + output_dim, dec_hid_dim, n_layers, batch_first=True)\n",
    "        # prediction을 위한 Linear 층\n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + output_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs, hidden_last_layer):\n",
    "        # 차원 맞추기\n",
    "        input = input.unsqueeze(1)\n",
    "        \n",
    "        # 실제로 인코더의 모든 hidden_state가 아닌 마지막 만을 받아와서 어텐션 가중치를 구하기 때문에 추가 변수 지정\n",
    "        attention_weights = self.attention(hidden_last_layer, encoder_outputs)\n",
    "        # 차원 맞추기\n",
    "        attention_weights = attention_weights.unsqueeze(1)\n",
    "        # bmm -> matmul과 매우 유사 하지만 bmm은 3차원 텐서에 관해서만 행렬 합을 할 수 있으며 브로드캐스팅을 지원안하는 것으로 알고있습니다. 아마..?\n",
    "        weighted = torch.bmm(attention_weights, encoder_outputs)\n",
    "        # rnn_input으로 들어갈 입력데이터와 가중치를 행렬합을 함\n",
    "        # 이렇게 해야 디코더의 모든 시퀀스에 대하여 어텐션 가중치를 적용가능\n",
    "        rnn_input = torch.cat((input, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        # 차원 맞추기\n",
    "        embedded = input.squeeze(1)\n",
    "        output = output.squeeze(1)\n",
    "        weighted = weighted.squeeze(1)\n",
    "        # 임베딩과, 결과물과, 가중치를 행렬합 계산을 하고 Linear층을 통하여 예측함\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "\n",
    "        return prediction, (hidden, cell)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        # shape 지정\n",
    "        trg_len = trg.shape[1]\n",
    "        batch_size = trg.shape[0]\n",
    "        trg_dim = trg.shape[2]\n",
    "        # 0행렬을 만들어서 최종 결과물 shape의 형태의 텐서 생성\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_dim).to(self.device)\n",
    "        # src -> 입력데이터, source 즉 90일치 (예시, 윈도우 사이즈, 변경가능)의 데이터를 통하여 인코더의 결과물과 히든 스테이트, 셀스테이트를 리턴\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "\n",
    "        # 타겟데이터에서 입력으로 넣을 것만 추출\n",
    "        # trg = [batch_size, trg_len, 1]\n",
    "        input = trg[:, 0, :]\n",
    "        # print(f\"input 의 차원 : {input.shape}\")\n",
    "        \n",
    "        # 아래 반복을 한 이유\n",
    "        # 처음 모델을 제작할 시 n_layer 옵션을 걸지 않고 단순한 한층 구조를 만들어서 (n_layer=1) 하다보니 차원이 무조건 [1, batch_size, len]으로 고정\n",
    "        # 하지만 모델 고도화 작업 중 단층은 너무 별로지 않나 라는 생각을 하였고 하다보니 [n_layer, batch_size, len] 구조를 만들기 위한 reepat문으로 차원수를 맞춰주었음\n",
    "        hidden = hidden.unsqueeze(0).repeat(self.decoder.rnn.num_layers, 1, 1)\n",
    "        cell = cell.unsqueeze(0).repeat(self.decoder.rnn.num_layers, 1, 1)\n",
    "        # 층이 여러개다 보니까 마지막 층의 hidden_state 만사용하기 위하여 따로 변수로 추출\n",
    "        hidden_last_layer = hidden[-1]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            # 0행렬을 만들고 trg_len만큼의 길이만큼 반복하면서 각 time step별로 0행렬을 채워넣는 구조\n",
    "            # decoder forward 부분에 필요한 파라미터를 입력 인자로 결과물 추출\n",
    "            output, (hidden, cell) = self.decoder(input, hidden, cell, encoder_outputs, hidden_last_layer)\n",
    "            # 각 time step 별 결과물을 채움\n",
    "            outputs[:, t, :] = output\n",
    "            \n",
    "            # 교사 강요 (teacher forcing) 이러한 인코더 디코더 구조의 경우 너무 학습 속도가 느리다는 단점이 존재한다.\n",
    "            # 이를 해결하기 위해서 교사 강요를 사용해 학습 속도를 높였음\n",
    "            # 하지만 불안정한 학습으로 수렴할 수 있기 때문에 제거 고려해야함\n",
    "            # 원래라면 이러한 시퀀스 모델은 자기회귀 모델이기 때문에 첫번째 결과물이 두번째 입력값으로 들어가야한다.\n",
    "            # 이럴경우 21일을 예측하려면 21번의 시퀀스를 그대로 진행해야함\n",
    "            # 따라서 속도를 높이기 위하여 입력값의 경우 teacher_forcing_ratio 만큼 고정하여 학습을 하여 속도를 올린다. -> 한국말이지만 제가 읽어도 모르겠기 때문에 이해안가면 말해주세요\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input = trg[:, t, :] if teacher_force else output\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 5\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYER = 4\n",
    "ENC_HID_DIM = 32\n",
    "DEC_HID_DIM = 32\n",
    "DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYER, DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYER, DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Scheduler\n",
    "class WarmupLR(optim.lr_scheduler.LambdaLR):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: optim.Optimizer,\n",
    "        warmup_end_steps: int,\n",
    "        last_epoch: int = -1,\n",
    "    ):\n",
    "        \n",
    "        def wramup_fn(step: int):\n",
    "            if step < warmup_end_steps:\n",
    "                return float(step) / float(max(warmup_end_steps, 1))\n",
    "            return 1.0\n",
    "        \n",
    "        super().__init__(optimizer, wramup_fn, last_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = type(model).__name__\n",
    "\n",
    "# define loss\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# define optimizer\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer_name = type(optimizer).__name__\n",
    "\n",
    "# define scheduler\n",
    "# scheduler = WarmupLR(optimizer, 1500)\n",
    "scheduler = None\n",
    "scheduler_name = type(scheduler).__name__ if scheduler is not None else \"no\"\n",
    "\n",
    "max_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_value = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_dataloader, val_dataloader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    best_loss = 9999999\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, 2):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for X, Y in tqdm(iter(train_dataloader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            # y의 경우 현재 [batch_size, 21]로 구성 unsqueeze를 통해 3번째 차원 (인덱스 2)를 만들어줘야함\n",
    "            Y = Y.unsqueeze(2)\n",
    "            # 이렇게 하면 [batch_size, 21, 1] 로 변시ㅣㄴ\n",
    "            \n",
    "            # Foward\n",
    "            optimizer.zero_grad()\n",
    "            # get prediction\n",
    "            # **주의사항**\n",
    "            # 모델 학습시 x, y 둘다 넣어 줘야합니다.\n",
    "            output = model(X, Y)\n",
    "            \n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            # Apply gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            # Perform LR scheduler Work\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss = validation(model, val_dataloader, criterion, device)\n",
    "        print(f'Epoch : [{epoch}] Train Loss : [{np.mean(train_loss):.5f}] Val Loss : [{val_loss:.5f}]')\n",
    "        \n",
    "        if best_loss > val_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model = model\n",
    "            print('Model Saved')\n",
    "        \n",
    "        # # WandB logging\n",
    "        # wandb.log({\n",
    "        #     \"Epoch\": epoch,\n",
    "        #     \"Train Loss\": np.mean(train_loss),\n",
    "        #     \"Validation Loss\": val_loss,\n",
    "        # })\n",
    "        \n",
    "    return best_model\n",
    "\n",
    "def validation(model, val_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in tqdm(iter(val_dataloader)):\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            Y = Y.unsqueeze(2)\n",
    "\n",
    "            output = model(X, Y)\n",
    "            loss = criterion(output, Y)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bae278127945569babda7425a78ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/883 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3060a6ee98314d94a790195f9dc10cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [1] Train Loss : [0.01401] Val Loss : [0.01342]\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "infer_model = train(model, optimizer, train_dataloader, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_input, None)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추론이 조금 많이 변경됨\n",
    "- 기존의 경우 모델에 X값만 넣으면 되는데 이 모델의 경우 src와 trg두개를 넣어야 학습이 된다.\n",
    "- 따라서 기존의 model(x) 만 입력하면 되는 추론에서 직접 마지막 deocder의 forward 구조를 조금 변경하여서 추론 코드를 작성하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, src, max_len=21):\n",
    "    model.eval() \n",
    "    src = src.to(device)\n",
    "    src_len = src.shape[1]\n",
    "\n",
    "    \n",
    "    encoder_outputs, hidden_cell = model.encoder(src)\n",
    "\n",
    "    hidden = hidden_cell[0].unsqueeze(0).repeat(N_LAYER, 1, 1)\n",
    "    cell = hidden_cell[1].unsqueeze(0).repeat(N_LAYER, 1, 1)\n",
    "    hidden_last_layer = hidden[-1]\n",
    "    input = src[:, 0, :]\n",
    "\n",
    "    outputs = []\n",
    "    \n",
    "    for t in range(max_len):\n",
    "        \n",
    "        input_dim = input.shape[-1]\n",
    "        if input_dim != OUTPUT_DIM:\n",
    "            \n",
    "            input = input[:, :OUTPUT_DIM]\n",
    "        output, (hidden, cell) = model.decoder(input, hidden, cell, encoder_outputs, hidden_last_layer)\n",
    "        outputs.append(output.unsqueeze(1))\n",
    "        \n",
    "        input = output\n",
    "\n",
    "    return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 21, 1])\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_dataloader):\n",
    "    model.eval() \n",
    "\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        for src in test_dataloader:\n",
    "            src = src.to(device)\n",
    "            predictions = inference(model, src)\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "    return torch.cat(all_predictions, dim=0)\n",
    "\n",
    "all_predictions = evaluate(infer_model, test_dataloader)\n",
    "\n",
    "print(all_predictions.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = all_predictions.squeeze(2).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론 결과를 inverse scaling\n",
    "for idx in range(len(pred)):\n",
    "    pred[idx, :] = pred[idx, :] * (scale_max_dict[idx] - scale_min_dict[idx]) + scale_min_dict[idx]\n",
    "    \n",
    "# 결과 후처리\n",
    "pred = np.round(pred, 0).astype(int)\n",
    "\n",
    "# 학습하다보니 0이하인 값이 많이 발생\n",
    "# -> 물론 에포크 한번만 돌리고 데이터도 100개로 했음\n",
    "# 아무튼 판매량인데 0이하가 말이되나 하고 후처리 하나 추가\n",
    "pred[pred < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8,  6,  3, ...,  2,  2,  2],\n",
       "       [ 9,  6,  3, ...,  2,  2,  2],\n",
       "       [40, 24, 14, ...,  7,  7,  7],\n",
       "       ...,\n",
       "       [ 8,  5,  3, ...,  1,  1,  1],\n",
       "       [ 2,  2,  1, ...,  4,  4,  4],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
